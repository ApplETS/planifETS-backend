{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Program Files\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy==1.26 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (1.5.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (5.24.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: transformers==4.46.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (4.46.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.3.1)\n",
      "Requirement already satisfied: einops in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.8.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.1.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (5.7.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (3.4.2)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (0.5.7)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (8.1.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (0.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from transformers==4.46.3) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from plotly) (8.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: Pillow in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.115.5)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.5.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (1.5.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (3.10.6)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.7.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.5.2)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from gradio-client==1.5.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from umap-learn) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers==4.46.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers==4.46.3) (2.2.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\antoi\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (C:\\Users\\antoi\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch numpy==1.26 pandas scikit-learn plotly nltk transformers==4.46.3 sentence-transformers einops datasets gradio networkx umap-learn ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import display\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.preprocessing import normalize\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "# Tomas Mazak's workaround\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "display(HTML(\n",
    "\"\"\"\n",
    "<script type=\"text/javascript\" async\n",
    "src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-M\">\n",
    "\"\"\"\n",
    "))\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\antoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\antoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\antoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize into words\n",
    "    words = word_tokenize(text.lower())\n",
    "    # Remove stopwords and non-alphabetic tokens\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    sentences = sent_tokenize(text, language='french')\n",
    "    return ' '.join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove stopwords\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    remove_stopwords(text)\n",
    "    return text.strip()\n",
    "    return no_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV files to inspect their contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_df = pd.read_csv(os.path.join(current_dir, 'Program.csv'))\n",
    "program_df['title'] = program_df['title'].str.replace(r'<[^>]*>', '', regex=True)\n",
    "program_course_df = pd.read_csv(os.path.join(current_dir, 'ProgramCourse.csv'))\n",
    "program_type_df = pd.read_csv(os.path.join(current_dir, 'ProgramType.csv'))\n",
    "course_df = pd.read_csv(os.path.join(current_dir, 'Course.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MiniLM model and tokenizer for generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(250037, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"nvidia/NV-Embed-v2\", trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(\"nvidia/NV-Embed-v2\", trust_remote_code=True)\n",
    "# # Move model to GPU if available for faster computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Function to Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(250037, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize device outside the embedding function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(\n",
    "    text_list, tokenizer, model, device=device, batch_size=32, pooling='mean', preprocess_fn=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of texts using the specified pooling strategy.\n",
    "\n",
    "    Args:\n",
    "        text_list (list of str): List of input texts.\n",
    "        tokenizer (transformers.AutoTokenizer): Tokenizer corresponding to the model.\n",
    "        model (transformers.AutoModel): Pre-trained language model.\n",
    "        device (torch.device): Device to perform computations on.\n",
    "        batch_size (int, optional): Number of texts to process per batch. Defaults to 32.\n",
    "        pooling (str, optional): Pooling strategy ('mean', 'max', 'concat'). Defaults to 'mean'.\n",
    "        preprocess_fn (callable, optional): Preprocessing function for text. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Generated embeddings.\n",
    "    \"\"\"\n",
    "    if pooling not in ['mean', 'max', 'concat']:\n",
    "        raise ValueError(f\"Unsupported pooling type '{pooling}'. Choose from 'mean', 'max', 'concat'.\")\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    embeddings = []\n",
    "\n",
    "    # Preprocess text if a function is provided\n",
    "    if preprocess_fn:\n",
    "        text_list = [preprocess_fn(text) for text in text_list]\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i in range(0, len(text_list), batch_size):\n",
    "            batch_texts = text_list[i:i + batch_size]\n",
    "\n",
    "            # Tokenize each text into sentences if too long\n",
    "            tokenized_texts = [\n",
    "                sent_tokenize(text) if len(text.split()) > 512 else [text] for text in batch_texts\n",
    "            ]\n",
    "            \n",
    "            # Embed each sentence separately and aggregate\n",
    "            batch_embeddings = []\n",
    "            for sentences in tokenized_texts:\n",
    "                # Tokenize and process sentences\n",
    "                tokens = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "                tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "                outputs = model(**tokens)\n",
    "\n",
    "                # Pool embeddings at sentence level\n",
    "                if pooling == 'mean':\n",
    "                    sentence_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "                elif pooling == 'max':\n",
    "                    sentence_embeddings = outputs.last_hidden_state.max(dim=1).values\n",
    "                elif pooling == 'concat':\n",
    "                    mean_pool = outputs.last_hidden_state.mean(dim=1)\n",
    "                    max_pool = outputs.last_hidden_state.max(dim=1).values\n",
    "                    sentence_embeddings = torch.cat((mean_pool, max_pool), dim=1)\n",
    "                \n",
    "                # Aggregate sentence embeddings\n",
    "                text_embedding = sentence_embeddings.mean(dim=0)\n",
    "                batch_embeddings.append(text_embedding)\n",
    "\n",
    "            # Append batch embeddings\n",
    "            embeddings.append(torch.stack(batch_embeddings).cpu())\n",
    "\n",
    "    # Concatenate all batch embeddings\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = normalize(embeddings.numpy(), axis=1)\n",
    "\n",
    "    print(f\"Generated embeddings with '{pooling}' pooling. Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings for Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with 'mean' pooling. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# List of columns to include\n",
    "columns_to_include = [\n",
    "    'title', 'code', 'cycle', 'url', 'id'\n",
    "]\n",
    "\n",
    "# Ensure all columns are strings and handle NaN values\n",
    "for col in columns_to_include:\n",
    "    program_df[col] = program_df[col].astype(str).fillna('')\n",
    "\n",
    "# Concatenate the columns into a single string for each program\n",
    "program_texts = program_df[columns_to_include].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Generate embeddings for the combined texts\n",
    "program_embeddings = generate_embeddings(program_texts.tolist(), tokenizer, model)\n",
    "\n",
    "# Add embeddings to program_df\n",
    "program_df['vector'] = list(program_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca = PCA(n_components=2, random_state=42)\n",
    "program_pca_result = pca.fit_transform(program_embeddings)\n",
    "program_df['pca-one-program'] = program_pca_result[:, 0]\n",
    "program_df['pca-two-program'] = program_pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=42)\n",
    "program_tsne_result = tsne.fit_transform(program_embeddings)\n",
    "program_df['tsne-one-program'] = program_tsne_result[:, 0]\n",
    "program_df['tsne-two-program'] = program_tsne_result[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize UMAP with desired parameters\n",
    "umap_projection = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit and transform the program embeddings\n",
    "program_umap_result = umap_projection.fit_transform(program_embeddings)\n",
    "\n",
    "# Add UMAP results to your DataFrame\n",
    "program_df['umap-one-program'] = program_umap_result[:, 0]\n",
    "program_df['umap-two-program'] = program_umap_result[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate Embeddings for Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with 'mean' pooling. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# List of columns to include\n",
    "columns_to_include = [\n",
    "    'code', 'title', 'description', 'cycle', 'credits'\n",
    "]\n",
    "\n",
    "# Ensure all columns are strings and handle NaN values\n",
    "for col in columns_to_include:\n",
    "    course_df[col] = course_df[col].astype(str).fillna('')\n",
    "\n",
    "# Concatenate the columns into a single string for each program\n",
    "course_texts = course_df[columns_to_include].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Generate embeddings for the combined texts\n",
    "course_embeddings = generate_embeddings(course_texts.tolist(), tokenizer, model)\n",
    "\n",
    "# Add embeddings to program_df\n",
    "course_df['vector'] = list(course_embeddings)\n",
    "\n",
    "vectors = np.stack(course_df['vector'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Embeddings using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca = PCA(n_components=2, random_state=42)\n",
    "course_pca_result = pca.fit_transform(course_embeddings)\n",
    "course_df['pca-one-course'] = course_pca_result[:, 0]\n",
    "course_df['pca-two-course'] = course_pca_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Embeddings using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, max_iter=1000, random_state=42)\n",
    "course_tsne_result = tsne.fit_transform(course_embeddings)\n",
    "course_df['tsne-one-course'] = course_tsne_result[:, 0]\n",
    "course_df['tsne-two-course'] = course_tsne_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize UMAP with desired parameters\n",
    "umap_projection = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit and transform the course embeddings\n",
    "course_umap_result = umap_projection.fit_transform(course_embeddings)\n",
    "\n",
    "# Add UMAP results to your DataFrame\n",
    "course_df['umap-one-course'] = course_umap_result[:, 0]\n",
    "course_df['umap-two-course'] = course_umap_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect the Programs and Courses using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure consistent data types for merge keys\n",
    "program_course_df['courseId'] = program_course_df['courseId'].astype(str)\n",
    "course_df['id'] = course_df['id'].astype(str)\n",
    "\n",
    "program_course_df['programId'] = program_course_df['programId'].astype(str)\n",
    "program_df['id'] = program_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after merging program_course_df and program_df:\n",
      "['createdAt_program_course', 'updatedAt_program_course', 'typicalSessionIndex', 'courseId', 'programId', 'type', 'code', 'credits', 'horaireCoursPdfJson', 'planificationPdfJson', 'createdAt_program', 'updatedAt_program', 'title', 'url', 'cycle', 'id', 'vector', 'pca-one-program', 'pca-two-program', 'tsne-one-program', 'tsne-two-program', 'umap-one-program', 'umap-two-program']\n"
     ]
    }
   ],
   "source": [
    "# Merge DataFrames with suffixes to differentiate columns\n",
    "combined_df = pd.merge(\n",
    "    program_course_df,\n",
    "    program_df,\n",
    "    left_on='programId',\n",
    "    right_on='id',\n",
    "    how='left',\n",
    "    suffixes=('_program_course', '_program')\n",
    ")\n",
    "\n",
    "# Print columns after first merge\n",
    "print(\"Columns after merging program_course_df and program_df:\")\n",
    "print(combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after merging with course_df:\n",
      "['createdAt_program_course', 'updatedAt_program_course', 'typicalSessionIndex', 'courseId', 'programId', 'type', 'code', 'credits', 'horaireCoursPdfJson', 'planificationPdfJson', 'createdAt_program', 'updatedAt_program', 'title', 'url', 'cycle', 'id', 'vector', 'pca-one-program', 'pca-two-program', 'tsne-one-program', 'tsne-two-program', 'umap-one-program', 'umap-two-program', 'code_course', 'title_course', 'description', 'credits_course', 'createdAt', 'updatedAt', 'id_course', 'cycle_course', 'vector_course', 'pca-one-course', 'pca-two-course', 'tsne-one-course', 'tsne-two-course', 'umap-one-course', 'umap-two-course']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge with course_df\n",
    "combined_df = pd.merge(\n",
    "    combined_df,\n",
    "    course_df,\n",
    "    left_on='courseId',\n",
    "    right_on='id',\n",
    "    how='left',\n",
    "    suffixes=('', '_course')\n",
    ")\n",
    "\n",
    "# Print columns after second merge\n",
    "print(\"Columns after merging with course_df:\")\n",
    "print(combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Rename columns for clarity\n",
    "combined_df.rename(columns={\n",
    "    'title': 'title_program',\n",
    "    'code': 'code_program',\n",
    "    'cycle': 'cycle_program',\n",
    "    'credits': 'credits_program',\n",
    "    'horaireCoursPdfJson': 'horaireCoursPdfJson_program',\n",
    "    'title_course': 'title_course',\n",
    "    'code_course': 'code_course',\n",
    "    'cycle_course': 'cycle_course',\n",
    "    'credits_course': 'credits_course',\n",
    "    'description': 'description_course'\n",
    "}, inplace=True)\n",
    "\n",
    "# Updated list of columns to include in the combined text\n",
    "columns_to_include = [\n",
    "    'programId', 'courseId', 'type',\n",
    "    'title_program', 'code_program', 'cycle_program', 'credits_program', 'horaireCoursPdfJson_program',\n",
    "    'title_course', 'code_course', 'cycle_course', 'credits_course', 'description_course'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with 'mean' pooling. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Ensure all columns are strings and handle NaN values\n",
    "for col in columns_to_include:\n",
    "    combined_df[col] = combined_df[col].astype(str).fillna('')\n",
    "\n",
    "# Concatenate the columns into a single string for each record\n",
    "combined_texts = combined_df[columns_to_include].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Generate embeddings for the combined texts\n",
    "combined_embeddings = generate_embeddings(combined_texts.tolist(), tokenizer, model)\n",
    "\n",
    "# Add embeddings to combined_df\n",
    "combined_df['vector'] = list(combined_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca = PCA(n_components=2, random_state=42)\n",
    "combined_pca_result = pca.fit_transform(combined_embeddings)\n",
    "combined_df['pca-one-combined'] = combined_pca_result[:, 0]\n",
    "combined_df['pca-two-combined'] = combined_pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=50, max_iter=1000, random_state=42)\n",
    "combined_tsne_result = tsne.fit_transform(combined_embeddings)\n",
    "combined_df['tsne-one-combined'] = combined_tsne_result[:, 0]\n",
    "combined_df['tsne-two-combined'] = combined_tsne_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique programs: 44\n"
     ]
    }
   ],
   "source": [
    "# Check the number of unique programs\n",
    "num_unique_programs = combined_df['title_program'].nunique()\n",
    "print(f\"Number of unique programs: {num_unique_programs}\")\n",
    "\n",
    "# Initialize UMAP with desired parameters\n",
    "umap_projection = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1)\n",
    "\n",
    "# Fit and transform the combined embeddings\n",
    "combined_umap_result = umap_projection.fit_transform(combined_embeddings)\n",
    "\n",
    "# Add UMAP results to the DataFrame\n",
    "combined_df['umap-one-combined'] = combined_umap_result[:, 0]\n",
    "combined_df['umap-two-combined'] = combined_umap_result[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement KNN to Find Similar Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10)\n",
    "knn.fit(vectors)\n",
    "\n",
    "def find_similar_courses(index, n_neighbors=5):\n",
    "    course_embedding = vectors[index].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(course_embedding, n_neighbors=n_neighbors+1)\n",
    "    similar_courses = []\n",
    "    for i in range(1, len(indices[0])):\n",
    "        idx = indices[0][i]\n",
    "        similar_courses.append({\n",
    "            'course_id': course_df.iloc[idx]['id'],\n",
    "            'title': course_df.iloc[idx]['title'],\n",
    "            'cycle': course_df.iloc[idx]['cycle'],\n",
    "            'distance': distances[0][i]\n",
    "        })\n",
    "        \n",
    "    return similar_courses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses similar to 'Analytiques des données massives' in cycle '2 (ID: Ce cours présente les concepts pour effectuer une analyse statistique de très grands ensembles de données qui ne tiennent pas sur un seul ordinateur. Ce cours vous permettra développer vos connaissances en analyse de données massives et améliorerez vos compétences en programmation et en mathématiques. Vous apprendrez à utiliser des outils analytiques essentiels pour l’analyse statistique des données massives. Plusieurs problèmes applicatifs seront étudiés et différentes...):\n",
      "- Introduction à l’analyse des mégadonnées (Cycle: 1, Description: 352303, Distance: 0.1462)\n",
      "- Maîtrise statistique des procédés (Cycle: 1, Description: 351867, Distance: 0.2465)\n",
      "- Analyse de données et systèmes prédictifs (Cycle: 2, Description: 350753, Distance: 0.2503)\n",
      "- Informatique et statistiques appliquées (Cycle: 1, Description: 352663, Distance: 0.2550)\n",
      "- Entrepôts de données et intelligence d’affaires (Cycle: 2, Description: 353322, Distance: 0.2639)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "index_to_query = 2\n",
    "similar_courses = find_similar_courses(index_to_query, n_neighbors=5)\n",
    "\n",
    "queried_course = course_df.iloc[index_to_query]\n",
    "print(f\"Courses similar to '{queried_course['title']}' in cycle '{queried_course['cycle']} (ID: {queried_course['description']}):\")\n",
    "for course in similar_courses:\n",
    "    print(f\"- {course['title']} (Cycle: {course['cycle']}, Description: {course['course_id']}, Distance: {course['distance']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from combined_df\n",
    "combined_vectors = np.stack(combined_df['vector'].values)\n",
    "\n",
    "# Initialize KNN with cosine distance\n",
    "knn_combined = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10)\n",
    "\n",
    "# Fit KNN on combined embeddings\n",
    "knn_combined.fit(combined_vectors)\n",
    "\n",
    "def find_similar_combinations(index, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Find similar program-course combinations based on embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - index (int): Index of the record in combined_df to query.\n",
    "    - n_neighbors (int): Number of similar combinations to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries containing details of similar combinations.\n",
    "    \"\"\"\n",
    "    # Validate the index\n",
    "    if index < 0 or index >= len(combined_df):\n",
    "        raise IndexError(\"Index out of bounds for combined_df.\")\n",
    "\n",
    "    # Get the embedding for the specified index\n",
    "    combination_embedding = combined_vectors[index].reshape(1, -1)\n",
    "\n",
    "    # Find nearest neighbors (including the query itself)\n",
    "    distances, indices = knn_combined.kneighbors(combination_embedding, n_neighbors=n_neighbors + 1)\n",
    "\n",
    "    similar_combinations = []\n",
    "    for i in range(1, len(indices[0])):  # Start from 1 to exclude the query itself\n",
    "        idx = indices[0][i]\n",
    "        similar_combinations.append({\n",
    "            'program_id': combined_df.iloc[idx]['programId'],\n",
    "            'program_title': combined_df.iloc[idx]['title_program'],\n",
    "            'course_id': combined_df.iloc[idx]['courseId'],\n",
    "            'course_title': combined_df.iloc[idx]['title_course'],\n",
    "            'cycle': combined_df.iloc[idx]['cycle_course'],\n",
    "            'distance': distances[0][i]\n",
    "        })\n",
    "    return similar_combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program-Course combinations similar to 'Certificat en gestion immobilière' program and 'Gestion des actifs immobiliers' course in cycle '1' (Program ID: 182976, Course ID: 352245):\n",
      "\n",
      "- Program: Programme court en gestion immobilière (ID: 183016), Course: Gestion des actifs immobiliers (ID: 352245), Cycle: 1, Distance: 0.0207\n",
      "- Program: Programme court en gestion immobilière (ID: 183016), Course: Fondements et immobilier (ID: 352233), Cycle: 1, Distance: 0.1031\n",
      "- Program: Certificat en gestion immobilière (ID: 182976), Course: Gestion du personnel et relations industrielles (ID: 351827), Cycle: 1, Distance: 0.1234\n",
      "- Program: Programme court en gestion immobilière (ID: 183016), Course: Gestion du personnel et relations industrielles (ID: 351827), Cycle: 1, Distance: 0.1351\n",
      "- Program: Programme court en gestion immobilière (ID: 183016), Course: Planification et contrôle de projets (ID: 351065), Cycle: 1, Distance: 0.1416\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "index_to_query = 2  # Change this index based on your data\n",
    "\n",
    "try:\n",
    "    # Find similar program-course combinations\n",
    "    similar_combinations = find_similar_combinations(index_to_query, n_neighbors=5)\n",
    "\n",
    "    # Get details of the queried combination\n",
    "    queried_combination = combined_df.iloc[index_to_query]\n",
    "\n",
    "    print(f\"Program-Course combinations similar to '{queried_combination['title_program']}' \"\n",
    "          f\"program and '{queried_combination['title_course']}' course \"\n",
    "          f\"in cycle '{queried_combination['cycle_course']}' (Program ID: {queried_combination['programId']}, \"\n",
    "          f\"Course ID: {queried_combination['courseId']}):\\n\")\n",
    "\n",
    "    for combo in similar_combinations:\n",
    "        print(f\"- Program: {combo['program_title']} (ID: {combo['program_id']}), \"\n",
    "              f\"Course: {combo['course_title']} (ID: {combo['course_id']}), \"\n",
    "              f\"Cycle: {combo['cycle']}, Distance: {combo['distance']:.4f}\")\n",
    "except IndexError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One program recommandation of courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text into sentences using NLTK's sent_tokenize for French.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text, language='french')\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def preprocess_text_input(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text by removing stopwords and tokenizing.\n",
    "    \"\"\"\n",
    "    sentences = tokenize_sentences(text)\n",
    "    preprocessed = preprocess_text(sentences)\n",
    "    return preprocessed\n",
    "\n",
    "def embed_text(text):\n",
    "    \"\"\"\n",
    "    Generates embedding for a single piece of text.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
    "        outputs = model(**tokens)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embedding\n",
    "\n",
    "def find_similar_combinations_within_program(program_id, text_input=None, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Find similar program-course combinations within a specific program based on an optional text input.\n",
    "\n",
    "    Parameters:\n",
    "    - program_id (str): Identifier of the program to restrict the search.\n",
    "    - text_input (str): Optional text input to base similarity on.\n",
    "    - n_neighbors (int): Number of similar combinations to retrieve.\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries containing details of similar combinations.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter the DataFrame to include only the specified program\n",
    "    program_subset = combined_df[combined_df['programId'] == program_id]\n",
    "\n",
    "    if program_subset.empty:\n",
    "        raise ValueError(f\"No data found for program ID: {program_id}\")\n",
    "\n",
    "    # Step 2: Extract embeddings for the subset\n",
    "    subset_vectors = np.stack(program_subset['vector'].values)\n",
    "\n",
    "    # Step 3: Initialize and fit KNN on the subset\n",
    "    knn_program = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn_program.fit(subset_vectors)\n",
    "\n",
    "    # Step 4: Handle text input (if provided)\n",
    "    if text_input:\n",
    "        # Preprocess and embed the input text\n",
    "        preprocessed_text = preprocess_text_input(text_input)\n",
    "        input_embedding = embed_text(preprocessed_text)\n",
    "    else:\n",
    "        # If no text input, default to the first combination in the subset\n",
    "        input_embedding = subset_vectors[0].reshape(1, -1)\n",
    "\n",
    "    # Step 5: Perform KNN search\n",
    "    distances, indices = knn_program.kneighbors(input_embedding, n_neighbors=n_neighbors + 1)\n",
    "\n",
    "    # Step 6: Compile similar combinations (excluding the query itself)\n",
    "    similar_combinations = []\n",
    "    for i in range(1, len(indices[0])):  # Start from 1 to exclude the query itself\n",
    "        idx = indices[0][i]\n",
    "        combo = program_subset.iloc[idx]\n",
    "        similar_combinations.append({\n",
    "            'program_id': combo['programId'],\n",
    "            'program_title': combo['title_program'],\n",
    "            'course_id': combo['courseId'],\n",
    "            'course_title': combo['title_course'],\n",
    "            'cycle': combo['cycle_course'],\n",
    "            'distance': distances[0][i]\n",
    "        })\n",
    "\n",
    "    return similar_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_similar_combinations_within_program(program_id, text_input=None, n_neighbors=5):\n",
    "    try:\n",
    "        # Find similar combinations\n",
    "        similar_combinations = find_similar_combinations_within_program(\n",
    "            program_id=program_id,\n",
    "            text_input=text_input,\n",
    "            n_neighbors=n_neighbors\n",
    "        )\n",
    "\n",
    "        # Get the course IDs of similar combinations\n",
    "        similar_course_ids = [combo['course_id'] for combo in similar_combinations]\n",
    "\n",
    "        # Filter the DataFrame for the specified program\n",
    "        program_subset = combined_df[combined_df['programId'] == program_id]\n",
    "\n",
    "        # Create the base t-SNE scatter plot\n",
    "        fig = px.scatter(\n",
    "            program_subset,\n",
    "            x='tsne-one-combined',\n",
    "            y='tsne-two-combined',\n",
    "            color='title_program',\n",
    "            hover_data=['title_course'],\n",
    "            title=f\"'{program_id}' Embeddings with Similar Courses Highlighted\",\n",
    "            labels={\n",
    "                'tsne-one-combined': 't-SNE Dimension 1',\n",
    "                'tsne-two-combined': 't-SNE Dimension 2'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Highlight similar courses\n",
    "        similar_df = program_subset[program_subset['courseId'].isin(similar_course_ids)]\n",
    "        fig.add_trace(\n",
    "            px.scatter(\n",
    "                similar_df,\n",
    "                x='tsne-one-combined',\n",
    "                y='tsne-two-combined',\n",
    "                hover_data=['title_course']\n",
    "            ).data[0]\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "    except (IndexError, ValueError) as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Course: Intégrité intellectuelle (ID: 349682), Cycle: 1, Distance: 0.7037\n",
      "- Course: Conception orientée objet (ID: 352405), Cycle: 1, Distance: 0.7278\n",
      "- Course: Logique et mathématiques discrètes (ID: 352637), Cycle: 1, Distance: 0.7314\n",
      "- Course: Progiciels de gestion intégrée (ID: 352039), Cycle: 1, Distance: 0.7314\n",
      "- Course: Environnement, technologie et société (ID: 354038), Cycle: 1, Distance: 0.7466\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Calcul différentiel et intégral"
          ],
          [
           "Développement professionnel et santé et sécurité du travail en secteur informatique"
          ],
          [
           "Programmation et réseautique en génie des TI"
          ],
          [
           "Intégrité intellectuelle"
          ],
          [
           "Règles de base en santé et sécurité"
          ],
          [
           "Chimie et matériaux"
          ],
          [
           "Rédaction technique et communication en génie des TI"
          ],
          [
           "Introduction au génie des TI"
          ],
          [
           "Équations différentielles"
          ],
          [
           "Logique et mathématiques discrètes"
          ],
          [
           "Conception orientée objet"
          ],
          [
           "Statique et dynamique"
          ],
          [
           "Probabilités et statistiques"
          ],
          [
           "Algèbre linéaire et géométrie de l’espace"
          ],
          [
           "Analyse et conception de logiciels"
          ],
          [
           "Électricité et magnétisme"
          ],
          [
           "Structures de données et algorithmes"
          ],
          [
           "Traitement des signaux audiovisuels"
          ],
          [
           "Conception et évaluation des interfaces utilisateurs"
          ],
          [
           "Physique des ondes"
          ],
          [
           "Encadrement de la profession et éthique professionnelle"
          ],
          [
           "Imagerie numérique"
          ],
          [
           "Introduction à l'information quantique"
          ],
          [
           "Programmation compétitive"
          ],
          [
           "Bases de données multimédias"
          ],
          [
           "Gestion de projets et assurance de la qualité"
          ],
          [
           "Apprentissage machine quantique"
          ],
          [
           "Réseaux de communication IP"
          ],
          [
           "Analyse de rentabilité de projets"
          ],
          [
           "Architecture logicielle"
          ],
          [
           "Conception d’applications mobiles"
          ],
          [
           "Sécurité des logiciels"
          ],
          [
           "Réingénierie du logiciel"
          ],
          [
           "Conception de systèmes informatiques en temps réel"
          ],
          [
           "Systèmes intelligents et algorithmes"
          ],
          [
           "Architectures de calculs parallèles"
          ],
          [
           "Introduction à l'approche DevOps"
          ],
          [
           "Principes des systèmes d’exploitation et programmation système"
          ],
          [
           "Intergiciels pour applications distribués"
          ],
          [
           "Ingénierie et conception de jeux vidéo"
          ],
          [
           "Fondements des systèmes distribués"
          ],
          [
           "Infographie"
          ],
          [
           "Sujets émergents en génie logiciel"
          ],
          [
           "Programmation mathématique : patrons et algorithmes efficaces"
          ],
          [
           "Systèmes d'information dans les entreprises"
          ],
          [
           "Environnement, technologie et société"
          ],
          [
           "Sécurité des systèmes"
          ],
          [
           "Technologies de développement Internet"
          ],
          [
           "Principes et fondements de l’Internet des objets (IdO)"
          ],
          [
           "Commerce électronique"
          ],
          [
           "Sécurité des réseaux d'entreprise"
          ],
          [
           "Protection des renseignements personnels"
          ],
          [
           "Test d’intrusion"
          ],
          [
           "Progiciels de gestion intégrée"
          ],
          [
           "Aspects opérationnels des réseaux"
          ],
          [
           "Interfaces utilisateurs avancées"
          ],
          [
           "Apprentissage machine avancé"
          ],
          [
           "Infrastructures et services infonuagiques"
          ],
          [
           "Sujets émergents en technologie de l'information"
          ],
          [
           "Systèmes d’applications mobiles"
          ],
          [
           "Projets spéciaux"
          ],
          [
           "Projet de fin d’études en génie des technologies de l’information"
          ]
         ],
         "hovertemplate": "title_program=Baccalauréat en génie des technologies de l'information<br>t-SNE Dimension 1=%{x}<br>t-SNE Dimension 2=%{y}<br>title_course=%{customdata[0]}<extra></extra>",
         "legendgroup": "Baccalauréat en génie des technologies de l'information",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Baccalauréat en génie des technologies de l'information",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -17.822308,
          9.1154585,
          -6.028313,
          28.562021,
          25.031334,
          -27.98162,
          -3.078657,
          5.026906,
          -21.231777,
          -15.976052,
          -7.4036613,
          -17.633945,
          -5.676154,
          -15.568629,
          -5.8726287,
          -24.672466,
          -7.855316,
          -2.4327567,
          -3.3794851,
          -28.111425,
          16.674217,
          -4.8390584,
          -29.599241,
          -9.048756,
          3.3581986,
          0.083747104,
          -29.420752,
          4.4631605,
          15.65187,
          -6.8694167,
          7.725076,
          16.012634,
          0.9644442,
          -0.4974183,
          -10.258785,
          -12.4110985,
          6.8056383,
          -2.1493368,
          -5.492628,
          -0.55331856,
          1.2602538,
          -7.418084,
          1.9474283,
          -11.727994,
          4.2491727,
          12.683461,
          14.219646,
          3.5817,
          4.3143296,
          5.747162,
          14.554462,
          18.396269,
          16.231924,
          0.32550526,
          5.06363,
          -4.2273035,
          6.442253,
          3.9687533,
          4.8965526,
          6.083098,
          -2.8998291,
          3.596558
         ],
         "xaxis": "x",
         "y": [
          10.462338,
          -5.7424393,
          10.963517,
          -9.1463,
          9.581324,
          -8.331967,
          -10.63708,
          9.959831,
          9.251758,
          11.409717,
          4.8702736,
          -6.143535,
          0.37769398,
          7.37536,
          9.135847,
          13.782803,
          10.74083,
          28.523972,
          14.297479,
          7.7624927,
          -22.00993,
          19.517506,
          14.356772,
          9.043072,
          7.657411,
          -12.347315,
          15.08537,
          17.580214,
          -12.103449,
          -12.986593,
          14.377482,
          15.527344,
          8.775797,
          11.930858,
          10.949662,
          12.934602,
          5.190639,
          10.098269,
          12.745609,
          16.363789,
          13.394327,
          19.585083,
          9.754889,
          9.144221,
          7.81247,
          -0.41678116,
          13.594066,
          15.126895,
          12.376277,
          11.071381,
          13.4451065,
          12.126151,
          13.010072,
          5.880298,
          16.599607,
          16.175173,
          8.513294,
          13.392835,
          8.824281,
          16.184614,
          -12.929577,
          -11.378999
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Intégrité intellectuelle"
          ],
          [
           "Logique et mathématiques discrètes"
          ],
          [
           "Conception orientée objet"
          ],
          [
           "Environnement, technologie et société"
          ],
          [
           "Progiciels de gestion intégrée"
          ]
         ],
         "hovertemplate": "tsne-one-combined=%{x}<br>tsne-two-combined=%{y}<br>title_course=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          28.562021,
          -15.976052,
          -7.4036613,
          12.683461,
          0.32550526
         ],
         "xaxis": "x",
         "y": [
          -9.1463,
          11.409717,
          4.8702736,
          -0.41678116,
          5.880298
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "title_program"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "'182912' Embeddings with Similar Courses Highlighted"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "t-SNE Dimension 1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "t-SNE Dimension 2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "program_id_to_query = '182912'\n",
    "text_input = \"DevOps\"\n",
    "\n",
    "try:\n",
    "    similar_combinations = find_similar_combinations_within_program(\n",
    "        program_id=program_id_to_query,\n",
    "        text_input=text_input,\n",
    "        n_neighbors=5\n",
    "    )\n",
    "\n",
    "    queried_program = combined_df[combined_df['programId'] == program_id_to_query].iloc[0]\n",
    "    for combo in similar_combinations:\n",
    "        print(f\"- Course: {combo['course_title']} (ID: {combo['course_id']}), \"\n",
    "              f\"Cycle: {combo['cycle']}, Distance: {combo['distance']:.4f}\")\n",
    "    \n",
    "    # Optional: Visualize the results\n",
    "    visualize_similar_combinations_within_program(program_id_to_query, text_input, n_neighbors=5)\n",
    "except (IndexError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Map program titles to program IDs\n",
    "program_title_to_id = dict(zip(combined_df['title_program'], combined_df['programId']))\n",
    "\n",
    "# Map course titles to course IDs\n",
    "course_title_to_id = dict(zip(combined_df['title_course'], combined_df['courseId']))\n",
    "\n",
    "def find_and_visualize_similar_combinations(selected_program_title, text_input, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Function to find similar combinations and visualize the results.\n",
    "    \"\"\"\n",
    "    # Get program ID based on the selected title\n",
    "    program_id = program_title_to_id.get(selected_program_title)\n",
    "\n",
    "    if not program_id:\n",
    "        return \"Invalid program selection. Please choose a valid program.\"\n",
    "\n",
    "    try:\n",
    "        # Find similar combinations within the program\n",
    "        similar_combinations = find_similar_combinations_within_program(\n",
    "            program_id=program_id,\n",
    "            text_input=text_input,\n",
    "            n_neighbors=n_neighbors\n",
    "        )\n",
    "\n",
    "\n",
    "        # Display results\n",
    "        result_text = f\"'{selected_program_title}':\\n\\n\"\n",
    "        for combo in similar_combinations:\n",
    "            result_text += (\n",
    "                f\"- Course: {combo['course_title']} (Cycle: {combo['cycle']}), \"\n",
    "                f\"Distance: {combo['distance']:.4f}\\n\"\n",
    "            )\n",
    "        return result_text\n",
    "\n",
    "    except ValueError as e:\n",
    "        return str(e)\n",
    "\n",
    "# Define Gradio interface\n",
    "program_dropdown = gr.Dropdown(\n",
    "    label=\"Select a Program\",\n",
    "    choices=list(program_title_to_id.keys())\n",
    ")\n",
    "\n",
    "text_input = gr.Textbox(\n",
    "    label=\"Input Text for Similarity Search\",\n",
    "    placeholder=\"Enter a description or text to find similar courses...\"\n",
    ")\n",
    "\n",
    "n_neighbors_slider = gr.Slider(\n",
    "    label=\"Number of Similar Courses to Find\",\n",
    "    minimum=1,\n",
    "    maximum=10,\n",
    "    step=1,\n",
    "    value=5,\n",
    ")\n",
    "\n",
    "output_text = gr.Textbox(\n",
    "    label=\"Similarity Search Results\"\n",
    ")\n",
    "\n",
    "# Build Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=find_and_visualize_similar_combinations,\n",
    "    inputs=[program_dropdown, text_input, n_neighbors_slider],\n",
    "    outputs=output_text,\n",
    "    live=True,\n",
    "    title=\"Program-Course Similarity Search\",\n",
    "    description=\"Select a program, optionally enter text, and find similar course combinations.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
